<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
    <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Nerfies: Deformable Neural Radiance Fields</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="static/images/favicon.png">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">AffordGrasp: In-Context Affordance Reasoning for
                        Open-Vocabulary Task-Oriented Grasping in Clutter</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              Yingbo Tang<sup>1</sup>&nbsp; &nbsp; &nbsp;
            </span>
                        <span class="author-block">
              Shuaike Zhang<sup>2</sup>&nbsp; &nbsp; &nbsp;
            </span>
                        <span class="author-block">
              Xiaoshuai Hao<sup>3</sup>&nbsp; &nbsp; &nbsp;
            </span>
                        <span class="author-block">
              Pengwei Wang<sup>3</sup>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jianlong Wu<sup>2</sup>&nbsp; &nbsp; &nbsp;
            </span>
                        <span class="author-block">
              Zhongyuan Wang<sup>3</sup>&nbsp; &nbsp; &nbsp;
            </span>
                        <span class="author-block">
              Shanghang Zhang<sup>3,4</sup>&nbsp; &nbsp; &nbsp;
            </span>
                    </div>

                    <br>

                    <!--  Apartment        -->
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Institute of Automation, Chinese Academy of Sciences&nbsp;&nbsp;&nbsp; <sup>2</sup>Harbin Institute of Technology (Shenzhen)&nbsp;&nbsp;&nbsp;
              <sup>3</sup>Beijing Academy of Artificial Intelligence&nbsp;&nbsp;&nbsp; <sup>4</sup>State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University
            </span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                            <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                        </div>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Inferring affordance of an object and grasping it in a task-oriented way is essential for robots
                        to complete manipulation task. The affordance reveals where and how to grasp an object by
                        considering object functionality, which is the foundation for task-oriented grasping. Current
                        task-oriented methods often rely on extensive training data limited in specific tasks and
                        objects, which struggles to generalize to novel objects and complex scenes. This paper presents
                        a novel open-vocabulary grasping approach <b>AffordGrasp</b>, which leverages the reasoning
                        capabilities of vision language models (VLMs) to perform in-context affordance reasoning. Unlike
                        existing approaches that need the explicit task and object name, our method abstracts the task
                        from the implicit user instruction, enabling better interaction with humans in daily life. Based
                        on the reasoning results, the task-relevant object is identified and its part-level affordance
                        is grounded with a visual grounding module. Then the task-oriented grasp poses are generated on
                        the affordance area of the object. The effectiveness of our method is validated in both
                        simulation and real-world experiments.
                    </p>
                </div>
            </div>
        </div>

        <hr>

        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Framework</h2>
                <div class="pipeline">
                    <img
                            src="./static/images/figure_framework.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>Fig.2</b>
                </p>
            </div>
        </div>
        <hr>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">RealWorld Experiment Results</h2>
            </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="pipeline">
                    <img
                            src="./static/images/TABLE3.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>COMPARISON RESULTS OF DIFFERENT METHODS IN REAL-WORLD EXPERIMENTS</b>
                </p>
            </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="pipeline">
                    <img
                            src="./static/images/figure_realworld.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>The examples in real-world experiments, where the visualization of affordance grounding and
                        task-oriented grasp pose generation are provided.</b>
                </p>
            </div>
        </div>
        <hr>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">RealWorld Experiment Videos</h2>
                <div class="item"
                     style="display: flex; justify-content: center; align-items: center; gap: 15%;padding: 0 25%">
                    <!-- 视频 1 -->
                    <video id="bottle" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/bottle.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 2 -->
                    <video id="kettle" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/kettle.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 3 -->
                    <video id="knife" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/knife.mp4" type="video/mp4">
                    </video>
                </div>
                <br>
                <br>
                <div class="item"
                     style="display: flex; justify-content: center; align-items: center; gap: 15%;padding: 0 25%">
                    <!-- 视频 1 -->
                    <video id="mug" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/mug.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 2 -->
                    <video id="pan" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/pan.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 3 -->
                    <video id="racket" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/racket.mp4" type="video/mp4">
                    </video>
                </div>
                <br>
                <br>
                <div class="item"
                     style="display: flex; justify-content: center; align-items: center; gap: 15%;padding: 0 25%">
                    <!-- 视频 1 -->
                    <video id="screwdriver" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/screwdriver.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 2 -->
                    <video id="spatula" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/spatula.mp4" type="video/mp4">
                    </video>
                    <!-- 视频 3 -->
                    <video id="spoon" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/iros_demo/spoon.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
        <br>
        <hr>

        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Simulation Experiment Results</h2>
            </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="pipeline">
                    <img
                            src="./static/images/TABLE1.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>SIMULATION RESULTS OF DIFFERENT METHODS GRASPING SINGLE OBJECT</b>
                </p>
            </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="pipeline">
                    <img
                            src="./static/images/TABLE2.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>SIMULATION RESULTS OF DIFFERENT METHODS GRASPING IN CLUTTER</b>
                </p>
            </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="pipeline">
                    <img
                            src="./static/images/figure_simulation.png"
                            class="pipeline image"
                            alt="pipeline image"
                    />
                </div>
                <p>
                    <b>The cases of cluttered grasping in simulation. The affordances of target object are labeled with
                        red stars.</b>
                </p>
            </div>
        </div>
        <hr>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Simulation Experiment Videos</h2>
                <div class="item"
                     style="display: flex; justify-content: center; align-items: center; gap: 15%;padding: 0 25%">
                    <!-- 视频 1 -->
                    <video id="simulation_hammer" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/simulation_hammer.mp4" type="video/mp4">
                    </video>

                    <!-- 视频 2 -->
                    <video id="simulation_screwdriver" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/simulation_screwdriver.mp4" type="video/mp4">
                    </video>

                    <!-- 视频 3 -->
                    <video id="simulation_spoon" autoplay controls muted loop playsinline
                           style="width: 100%; height: auto; max-width: 100%;">
                        <source src="./static/videos/simulation_spoon.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content" style="text-align: center">
                    <p>
                        The source code of this website is borrowed from
                        <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
